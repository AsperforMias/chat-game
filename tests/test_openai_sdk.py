#!/usr/bin/env python3
"""
ç»Ÿä¸€AI APIæµ‹è¯•å·¥å…· (OpenAI SDKè§„èŒƒ)
"""
import asyncio
import sys

def test_openai_compatible_api():
    """æµ‹è¯•OpenAIå…¼å®¹çš„APIé…ç½®"""
    print("ğŸ¤– OpenAI SDKè§„èŒƒ - AI API æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # 1. æ£€æŸ¥é…ç½®
    try:
        import config
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æä¾›å•†: {config.AI_PROVIDER}")
        print(f"   æ¨¡å‹: {config.MODEL}")
        print(f"   APIå¯†é’¥: {config.API_KEY[:20]}...")
        print()
    except ImportError:
        print("âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°")
        return False
    
    # 2. æ£€æŸ¥OpenAIåº“
    try:
        import openai
        print("âœ… OpenAI SDK å·²å®‰è£…")
        print()
    except ImportError:
        print("âŒ OpenAI SDK æœªå®‰è£…")
        print("   è¯·è¿è¡Œ: pip install openai")
        return False
    
    # 3. APIç«¯ç‚¹é…ç½®
    api_configs = {
        "openai": {
            "base_url": None,
            "description": "OpenAI å®˜æ–¹API",
            "models": ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"]
        },
        "kimi": {
            "base_url": "https://api.moonshot.cn/v1",
            "description": "Kimi (æœˆä¹‹æš—é¢) API",
            "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"]
        },
        "deepseek": {
            "base_url": "https://api.deepseek.com/v1", 
            "description": "DeepSeek API",
            "models": ["deepseek-chat", "deepseek-coder"]
        },
        "zhipu": {
            "base_url": "https://open.bigmodel.cn/api/paas/v4",
            "description": "æ™ºè°±AI API",
            "models": ["glm-4", "glm-3-turbo"]
        },
        "qwen": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "description": "é€šä¹‰åƒé—® API", 
            "models": ["qwen-turbo", "qwen-plus", "qwen-max"]
        }
    }
    
    if config.AI_PROVIDER not in api_configs:
        print(f"âŒ ä¸æ”¯æŒçš„æä¾›å•†: {config.AI_PROVIDER}")
        print(f"   æ”¯æŒçš„æä¾›å•†: {', '.join(api_configs.keys())}")
        return False
    
    provider_config = api_configs[config.AI_PROVIDER]
    print(f"ğŸ”§ ä½¿ç”¨æä¾›å•†: {provider_config['description']}")
    if provider_config['base_url']:
        print(f"   APIç«¯ç‚¹: {provider_config['base_url']}")
    print(f"   æ¨èæ¨¡å‹: {', '.join(provider_config['models'])}")
    print()
    
    # 4. æµ‹è¯•APIè¿æ¥
    try:
        print("ğŸ§ª æµ‹è¯•APIè¿æ¥...")
        
        client_args = {"api_key": config.API_KEY}
        if provider_config["base_url"]:
            client_args["base_url"] = provider_config["base_url"]
        
        client = openai.OpenAI(**client_args)
        
        # æµ‹è¯•ç®€å•å¯¹è¯
        response = client.chat.completions.create(
            model=config.MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„åŠ©æ‰‹ï¼Œè¯·ç®€çŸ­å›å¤ã€‚"},
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
            ],
            max_tokens=50,
            temperature=0.7
        )
        
        if response.choices and response.choices[0].message.content:
            print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ!")
            print(f"   AIå›å¤: {response.choices[0].message.content.strip()}")
        else:
            print("âš ï¸  APIè¿æ¥æˆåŠŸä½†æ— æœ‰æ•ˆå›å¤")
            print(f"   å“åº”: {response}")
        print()
        
    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        print(f"   é”™è¯¯ç±»å‹: {type(e)}")
        
        # åˆ†æå¸¸è§é”™è¯¯
        error_msg = str(e).lower()
        if "401" in error_msg:
            print("   ğŸ’¡ å»ºè®®: APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®")
        elif "403" in error_msg:
            print("   ğŸ’¡ å»ºè®®: APIå¯†é’¥æƒé™ä¸è¶³æˆ–å·²è¿‡æœŸ")
        elif "404" in error_msg:
            print("   ğŸ’¡ å»ºè®®: æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
            print(f"       æ¨èæ¨¡å‹: {', '.join(provider_config['models'])}")
        elif "quota" in error_msg or "limit" in error_msg:
            print("   ğŸ’¡ å»ºè®®: APIé…é¢å·²ç”¨å®Œï¼Œè¯·æ£€æŸ¥è´¦æˆ·ä½™é¢")
        elif "connection" in error_msg:
            print("   ğŸ’¡ å»ºè®®: ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
        
        return False
    
    # 5. æ¨¡å‹éªŒè¯
    if config.MODEL in provider_config["models"]:
        print(f"âœ… æ¨¡å‹ '{config.MODEL}' æ˜¯è¯¥æä¾›å•†çš„æ¨èæ¨¡å‹")
    else:
        print(f"âš ï¸  æ¨¡å‹ '{config.MODEL}' ä¸åœ¨æ¨èåˆ—è¡¨ä¸­")
        print(f"   æ¨èæ¨¡å‹: {', '.join(provider_config['models'])}")
    print()
    
    print("ğŸ‰ APIæµ‹è¯•å®Œæˆ!")
    return True

async def test_ai_service():
    """æµ‹è¯•AIæœåŠ¡é›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•AIæœåŠ¡é›†æˆ...")
    
    try:
        from ai_service import AIService
        ai_service = AIService()
        
        # æµ‹è¯•è§’è‰²å›å¤
        response = await ai_service.get_character_response(
            "æ‘é•¿",
            "ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„æ‘é•¿ï¼Œè¯´è¯ç®€æ´æ˜äº†ï¼Œå…³å¿ƒæ‘æ°‘ã€‚",
            "ä½ å¥½ï¼Œæ‘é•¿ï¼",
            "ä½ åœ¨æ‘åº„ä¸­å¿ƒï¼Œå‘¨å›´æœ‰å¾ˆå¤šæ‘æ°‘åœ¨æ´»åŠ¨ã€‚"
        )
        
        print(f"âœ… AIæœåŠ¡æµ‹è¯•æˆåŠŸ!")
        print(f"   æ‘é•¿å›å¤: {response}")
        
    except Exception as e:
        print(f"âŒ AIæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

async def main():
    """ä¸»å‡½æ•°"""
    success = test_openai_compatible_api()
    
    if success:
        await test_ai_service()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ‚¨å¯ä»¥å¼€å§‹æ¸¸æˆäº†ã€‚")
        print("\nğŸš€ å¯åŠ¨æ¸¸æˆ: python main.py")
    else:
        print("\nâš ï¸  è¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡æ–°æµ‹è¯•ã€‚")

if __name__ == "__main__":
    asyncio.run(main())
